import os
import torch
import torch.utils.data as data
import numpy as np
from PIL import Image
from torchvision.datasets.folder import is_image_file, default_loader
import torchvision.transforms as transforms
from ptsemseg.loader import joint_transforms 
import pdb
import json

# weights when using median frequency balancing used in SegNet paper
# https://arxiv.org/pdf/1511.00561.pdf
# The numbers were generated by https://github.com/yandex/segnet-torch/blob/master/datasets/camvid-gen.lua
class_weight = torch.FloatTensor([0.58872014284134, 0.51052379608154, 2.6966278553009, 0.45021694898605, 1.1785038709641, 0.77028578519821, 2.4782588481903, 2.5273461341858, 1.0122526884079, 3.2375309467316, 4.1312313079834])
# mean and std
mean = [0.41189489566336, 0.4251328133025, 0.4326707089857]
std = [0.27413549931506, 0.28506257482912, 0.28284674400252]

classes = ['Sky', 'Building', 'Column-Pole', 'Road',
           'Sidewalk', 'Tree', 'Sign-Symbol', 'Fence', 'Car', 'Pedestrain',
           'Bicyclist', 'Void']


class LabelToLongTensor(object):
    def __call__(self, pic):
        if isinstance(pic, np.ndarray):
            # handle numpy array
            label = torch.from_numpy(pic).long()
        else:
            label = torch.ByteTensor(torch.ByteStorage.from_buffer(pic.tobytes()))
            label = label.view(pic.size[1], pic.size[0], 1)
            label = label.transpose(0, 1).transpose(0, 2).squeeze().contiguous().long()
        return label

class CamVid(data.Dataset):

    def __init__(self, root, split, is_transform=True, labeled_index=None, img_size=None, video=None, crop=False):
        self.root = root
        assert split in ('train', 'val', 'test')
        self.split = split
        self.labeled_index = labeled_index
        self.transform = transforms.Compose([transforms.ToTensor(),
                                            transforms.Normalize(mean=mean, std=std)])
        self.target_transform = LabelToLongTensor()
        self.crop = crop
        self.joint_transform = transforms.Compose([
                joint_transforms.JointRandomCrop(224), # commented for fine-tuning
                joint_transforms.JointRandomHorizontalFlip()
                ])
        self.loader = default_loader
        self.class_weight = class_weight
        self.classes = classes
        self.mean = mean
        self.std = std
        self.n_classes = 11

        self.imgs = json.load(open(self.root + 'data_split.json', 'r'))[self.split]['labeled']
        if labeled_index:
            self.imgs = [self.imgs[index] for index in labeled_index]
            

    def __getitem__(self, index):
        path = self.root+self.imgs[index]
        img = self.loader(path)
        target = Image.open(path.replace(self.split, self.split + 'annot'))
        if self.crop:
            img, target = self.joint_transform([img, target])
        if self.transform is not None:
            img = self.transform(img)
        target = self.target_transform(target)
        return img, target, self.imgs[index]

    def __len__(self):
        return len(self.imgs)

    def decode_segmap(self, temp, plot=False):
        Sky = [128, 128, 128]
        Building = [128, 0, 0]
        Pole = [192, 192, 128]
        Road = [128, 64, 128]
        Pavement = [60, 40, 222]
        Tree = [128, 128, 0]
        SignSymbol = [192, 128, 128]
        Fence = [64, 64, 128]
        Car = [64, 0, 128]
        Pedestrian = [64, 64, 0]
        Bicyclist = [0, 128, 192]
        Unlabelled = [0, 0, 0]

        label_colours = np.array([Sky, Building, Pole, Road,
                                  Pavement, Tree, SignSymbol, Fence, Car,
                                  Pedestrian, Bicyclist, Unlabelled])
        r = temp.copy()
        g = temp.copy()
        b = temp.copy()
        for l in range(0, self.n_classes):
            r[temp == l] = label_colours[l, 0]
            g[temp == l] = label_colours[l, 1]
            b[temp == l] = label_colours[l, 2]

        rgb = np.zeros((temp.shape[0], temp.shape[1], 3))
        rgb[:, :, 0] = r
        rgb[:, :, 1] = g
        rgb[:, :, 2] = b
        if plot:
            plt.imshow(rgb)
            plt.show()
        else:
            return rgb

